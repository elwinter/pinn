{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard modules.\n",
    "from importlib import import_module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import supplemental modules.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import project modules.\n",
    "import pinn.standard_plots as psp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the run ID (aka problem name).\n",
    "runid = \"lagaris01\"\n",
    "\n",
    "# Add the subdirectory for the run results to the module search path.\n",
    "run_path = os.path.join(\".\", runid)\n",
    "sys.path.append(run_path)\n",
    "\n",
    "# Import the problem definition from the run results directory.\n",
    "p = import_module(runid)\n",
    "\n",
    "# Read the run hyperparameters from the run results directory.\n",
    "import hyperparameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data.\n",
    "\n",
    "X_train = np.loadtxt(os.path.join(runid, \"X_train.dat\"))\n",
    "x_train = X_train  # 1-D, so p.ix not needed\n",
    "\n",
    "# Load the data locations and values (includes initial conditions).\n",
    "XY_data = np.loadtxt(os.path.join(runid, \"XY_data.dat\"))\n",
    "\n",
    "# Extract the initial conditions (everything after the coordinate values on each row).\n",
    "ic = XY_data[p.n_dim:]\n",
    "\n",
    "# Load the model-predicted values.\n",
    "ψ = []\n",
    "delψ = []\n",
    "for var_name in p.dependent_variable_names:\n",
    "    ψ.append(np.loadtxt(os.path.join(runid, \"%s_train.dat\" % var_name)))\n",
    "    delψ.append(np.loadtxt(os.path.join(runid, \"del_%s_train.dat\" % var_name)))\n",
    "\n",
    "# Load the loss function histories.\n",
    "losses_model = np.loadtxt(os.path.join(runid, \"losses_model.dat\"))\n",
    "losses_model_res = np.loadtxt(os.path.join(runid, \"losses_model_res.dat\"))\n",
    "losses_model_data = np.loadtxt(os.path.join(runid, \"losses_model_data.dat\"))\n",
    "losses = np.loadtxt(os.path.join(runid, \"losses.dat\"))\n",
    "losses_res = np.loadtxt(os.path.join(runid, \"losses_res.dat\"))\n",
    "losses_data = np.loadtxt(os.path.join(runid, \"losses_data.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the limits of the training domain.\n",
    "x_min = x_train[0]\n",
    "x_max = x_train[-1]\n",
    "\n",
    "# Extract the unique training point values (a grid is assumed).\n",
    "x_train_vals = np.unique(x_train)\n",
    "n_x_train_vals = len(x_train_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting options\n",
    "\n",
    "# Specify the size (width, height) (in inches) for individual subplots.\n",
    "SUBPLOT_WIDTH = 5.0\n",
    "SUBPLOT_HEIGHT = 5.0\n",
    "\n",
    "# Compute the coordinate plot tick locations and labels.\n",
    "XY_N_X_TICKS = 5\n",
    "XY_x_tick_pos = np.linspace(x_min, x_max, XY_N_X_TICKS)\n",
    "XY_x_tick_labels = [\"%.1f\" % x for x in XY_x_tick_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total loss function history.\n",
    "total_loss_figsize = (SUBPLOT_WIDTH*2, SUBPLOT_HEIGHT)\n",
    "plt.figure(figsize=total_loss_figsize)\n",
    "psp.plot_loss_functions(\n",
    "    [losses_res, losses_data, losses],\n",
    "    [\"$L_{res}$\", \"$L_{data}$\", \"$L$\"],\n",
    "    title=\"Total loss function history for %s\" % runid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coordinates of the training points at the initial time.\n",
    "n_start = n_x_train_vals\n",
    "x0 = XY_data[0]\n",
    "y0 = XY_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the analytical solution at the training points.\n",
    "y_analytical = p.Ψ_analytical(x_train)\n",
    "\n",
    "y_train = ψ[0]\n",
    "\n",
    "# Compute the error in the trained solution.\n",
    "y_err = y_train - y_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual, predicted, and absolute error in the solution.\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(x_train, y_train, label=\"$\\psi_t$\")\n",
    "ax1.plot(x_train, y_analytical, label=\"$\\psi_a$\")\n",
    "ax1.plot(x_train, y_err, label=\"$\\psi_{err}$\")\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(p.independent_variable_labels[0])\n",
    "ax1.set_ylabel(p.dependent_variable_labels[0])\n",
    "ax1.set_title(\"Trained and analytical solutions for lagaris01\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00353d7f30cefe116fc1bf1d52fbabca9f44d2df3e2eb8cf0d245f78f2264c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
